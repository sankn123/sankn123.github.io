(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[405],{5557:function(e,n,i){(window.__NEXT_P=window.__NEXT_P||[]).push(["/",function(){return i(6062)}])},3193:function(e,n,i){"use strict";i.d(n,{$:function(){return o},r:function(){return r}});var t=i(5893),a=(i(7294),i(1664)),s=i.n(a),r=function(e){var n=e.title,i=e.description,a=e.buttons;return(0,t.jsx)("div",{id:"contact",className:"bg-white py-5 px-5",children:(0,t.jsxs)("div",{className:"container",children:[(0,t.jsx)("h1",{className:"text-primary fw-bold",children:n}),(0,t.jsxs)("div",{className:"px-sm-5",children:[(0,t.jsx)("p",{children:i}),(0,t.jsx)("div",{className:"",children:a.map((function(e,n){return e.isPrimary?(0,t.jsx)(s(),{href:e.link,children:(0,t.jsx)("a",{className:"btn btn-primary my-1 mx-3",children:e.title})},n):(0,t.jsx)(s(),{href:e.link,children:(0,t.jsx)("a",{className:"btn btn-outline-primary my-1 mx-3",children:e.title})},n)}))})]})]})})},o=function(){return(0,t.jsx)("footer",{className:"bg-secondary text-center py-2 px-5",children:(0,t.jsx)("div",{className:"container text-muted",children:(0,t.jsxs)("small",{children:["\xa9 2021 "," ",(0,t.jsx)(s(),{href:"https://github.com/hashirshoaeb",children:(0,t.jsx)("a",{children:"hashirshoaeb"})}),". Open sourced with love under "," ",(0,t.jsx)(s(),{href:"https://github.com/hashirshoaeb/portfolio/blob/main/LICENSE",children:(0,t.jsx)("a",{children:"MIT"})})," "," License"]})})})}},7673:function(e,n,i){"use strict";i.d(n,{h:function(){return r}});var t=i(5893),a=i(9008),s=i.n(a),r=function(e){var n=e.seo;return(0,t.jsxs)(s(),{children:[(0,t.jsx)("title",{children:n.title}),(0,t.jsx)("meta",{name:"description",content:n.description}),(0,t.jsx)("meta",{property:"og:title",content:n.title}),(0,t.jsx)("meta",{property:"og:description",content:n.description}),(0,t.jsx)("meta",{property:"og:image",content:n.image}),(0,t.jsx)("meta",{property:"og:type",content:"website"})]})}},4067:function(e,n,i){"use strict";i.d(n,{HJ:function(){return h},jZ:function(){return o},PX:function(){return d},mf:function(){return r},Ok:function(){return m},G:function(){return s},q:function(){return l},KK:function(){return c}});var t="/_next/static/media/profile.af9ecfc5.png",a=i(3024),s={name:"Home",links:[{title:"About",link:"#about"},{title:"Projects",link:"#projects"},{title:"Research",link:"#research"},{title:"Contact",link:"#contact"},{title:"Links",link:"/links"}]},r={title:"Hey, I'm Sankalp",description:"An electrical engineer focused on integrating AI into real-world applications.",image:t,buttons:[{title:"Contact Me",link:"#contact",isPrimary:!0},{title:"Resume",link:"https://drive.google.com/file/d/11f6X9eGAgBmm1V0r9n4nIGSM4tad4qDT/view?usp=sharing",isPrimary:!1}]},o={title:"Who I am",description:["I am a final-year B.Tech student at the Indian Institute of Technology, Dharwad, majoring in Electrical Engineering. I am currently working as a research assistant at IIT Dharwad, working on Computer Vision problems. I love reading new research papers and implementing their findings into practical applications, constantly pushing the boundaries of my knowledge.","Alongside my research, I have completed two internships at different startups, which I thoroughly enjoyed. I love the startup environment because of the sense of ownership it provides in developing and delivering the end-to-end product.","When I'm not diving into research, I enjoy playing football and spending time gaming\u2014though CSGO was my favorite until CS-2 ruined it!"]},l={title:"Some of my Projects",cards:[{title:"Adding AI generated voiceovers to silent videos",description:"An easy to use script that uses VideoDB for scene indexing, OpenAI for script generation, and ElevenLabs for realistic audio voiceovers, transforming silent footage into dynamic and engaging content.",icons:[{icon:a.zhw,link:"https://github.com/sankn123/AI-voiceovers-to-silent-videos"}]},{title:"Chandrayaan-2 Image Super-Resolution",description:"A project focused on enhancing the resolution of images using Generative AI from Indian Space Research Organisation-ISRO's Chandrayaan-2 mission using real-life data.",icons:[{icon:a.zhw,link:"https://github.com/snjvn/Moon_Mapping_Cosmosoc"}]},{title:"Paper Implementations",description:"Few of my implementations of key research papers in deep learning.",icons:[{icon:a.zhw,link:"https://github.com/sankn123/DCGAN-Implementation"},{icon:a.zhw,link:"https://github.com/sankn123/Very-deep-convolutional-networks-for-large-scale-image-recognition-Implementation"},{icon:a.zhw,link:"https://github.com/sankn123/Transformer-From-Scratch"}]}]},c={title:"Research Interests",description:["I am working as a research assistant at IIT Dharwad, and my research interests lie in Computer Vision, Generative AI, and Natural Language Processing (NLP)."],publications:[{title:"TM-PATHVQA: 90000+ Textless Multilingual Questions for Medical Visual Question Answering",description:"Published at Interspeech 2024. This work focuses on a speech-based VQA system with multilingual spoken questions. We proposed a dataset with 98,397 multilingual spoken questions and answers based on 5,004 pathological images along with 70 hours of audio, containing spoken questions in English, German & French. Finally, this work benchmarks and compares TM-PathVQA systems implemented using various combinations of acoustic and image features.",link:"https://www.isca-archive.org/interspeech_2024/rajkhowa24_interspeech.pdf"},{title:"When Visual State Space Model Meets Backdoor Attacks",description:"Accepted at Winter Conference on Applications of Computer Vision (WACV) 2025. This work investigates the robustness of the state space model-Mamba against three well-known backdoor attacks: Badnet, Wanet, and Refool. Additionally, We proposed a novel attack using the Gram-Schmidt process for matrix decomposition, presenting three variants which is uniquely imperceptible, setting it apart from other, more detectable attacks, and achieves the highest attack success rate on the Mamba model to date.",link:""},{title:"AMamba: Enhancing Audio Reprsentation Learning Using State Space Model (Under Review)",description:"Submitted to Neurocomputing journal. This work introduces the first-ever Audio Mamba, a state-space model.",link:""},{title:"Adaptive Knowledge Fusion Ratio-Based Knowledge Distillation (Under Review)",description:"Submitted to Pattern Recognition journal. This work highlights a limitation of standard knowledge distillation and introduces a trainable approach to the fusion ratio.",link:""}]},d={title:"Get in touch",description:"Feel free to reach out directly by email at sankalp.nagaonkar@gmail.com.",buttons:[{title:"Email Me",link:"mailto:sankalp.nagaonkar@gmail.com",isPrimary:!0}]},h={title:"Sankalp Nagaonkar",image:t},m={image:t,title:"@sankn123",description:"Electrical Engineer | AI Enthusiast | Computer Vision and Generative AI",cards:[{title:"Twitter",link:"https://x.com/sankn123/"},{title:"GitHub",link:"https://github.com/sankn123/"},{title:"LinkedIn",link:"https://linkedin.com/in/sankalp-nagaonkar-18343823b/"},{title:"Google Scholar",link:"https://scholar.google.com/citations?user=sCr-DQgAAAAJ&hl=en"}]}},6062:function(e,n,i){"use strict";i.r(n),i.d(n,{default:function(){return j}});var t=i(5893),a=i(7294),s=i(1664),r=i.n(s),o=function(e){var n=e.title,i=e.links,s=(0,a.useState)(!0),o=s[0],l=s[1];return(0,t.jsx)("nav",{className:"navbar navbar-expand-sm navbar-light bg-secondary",children:(0,t.jsxs)("div",{className:"container",children:[(0,t.jsx)(r(),{href:"/",children:(0,t.jsx)("a",{className:"navbar-brand",children:(0,t.jsx)("span",{className:"",children:n})})}),(0,t.jsx)("button",{className:"custom-toggler navbar-toggler",type:"button","data-toggle":"collapse","data-target":"#navbarsExample09","aria-controls":"navbarsExample09","aria-expanded":!o,"aria-label":"Toggle navigation",onClick:function(){return l(!o)},children:(0,t.jsx)("span",{className:"navbar-toggler-icon"})}),(0,t.jsx)("div",{className:"".concat(o?"collapse":""," navbar-collapse"),id:"navbarsExample09",children:(0,t.jsx)("div",{className:"navbar-nav",children:i.map((function(e,n){return(0,t.jsx)(r(),{href:e.link,children:(0,t.jsx)("a",{className:"nav-link",children:e.title})},n)}))})})]})})},l=i(1752),c=(i.n(l)()().publicRuntimeConfig,function(e){var n=e.title,i=e.description,a=e.image,s=e.buttons;return(0,t.jsx)("div",{className:"bg-secondary py-5 px-5",children:(0,t.jsx)("div",{className:"container",children:(0,t.jsxs)("div",{className:" row align-items-center",children:[(0,t.jsxs)("div",{className:"col-sm-6",children:[(0,t.jsx)("h1",{className:"text-primary fw-bold display-3",children:n}),(0,t.jsx)("p",{children:i}),(0,t.jsx)("div",{className:"text-center",children:s.map((function(e,n){return e.isPrimary?(0,t.jsx)(r(),{href:e.link,children:(0,t.jsx)("a",{className:"btn btn-primary my-1 mx-3",children:e.title})},n):(0,t.jsx)(r(),{href:e.link,children:(0,t.jsx)("a",{target:"_blank",rel:"noreferrer",className:"btn btn-outline-primary my-1 mx-3",children:e.title})},n)}))})]}),(0,t.jsx)("div",{className:"col-sm-6 text-center",children:(0,t.jsx)("img",{className:"img-fluid my-3 card-image",width:"250",height:"250",src:a,alt:"profile of Sankalp Nagaonkar"})})]})})})}),d=function(e){var n=e.title,i=e.description;return(0,t.jsx)("div",{id:"about",className:"bg-white py-5 px-5",children:(0,t.jsxs)("div",{className:"container",children:[(0,t.jsx)("h1",{className:"text-primary fw-bold",children:n}),(0,t.jsx)("div",{className:"px-sm-5",children:i.map((function(e,n){return(0,t.jsx)("p",{children:e},n)}))})]})})},h=function(e){var n=e.title,i=e.description,a=e.publications;return(0,t.jsx)("div",{id:"research",className:"bg-white py-5 px-5",children:(0,t.jsxs)("div",{className:"container",children:[(0,t.jsx)("h1",{className:"text-primary fw-bold",children:n}),(0,t.jsx)("div",{className:"px-sm-5",children:i.map((function(e,n){return(0,t.jsx)("p",{children:e},n)}))}),a&&a.length>0&&(0,t.jsxs)("div",{className:"mt-4",children:[(0,t.jsx)("h2",{className:"text-danger fw-bold",children:"Publications"}),(0,t.jsx)("ul",{className:"list-unstyled px-sm-5",children:a.map((function(e,n){return(0,t.jsxs)("li",{className:"mb-3",children:[(0,t.jsx)("h4",{className:"fw-bold",children:e.title}),(0,t.jsx)("p",{children:e.description}),e.link&&(0,t.jsx)("a",{href:e.link,target:"_blank",rel:"noopener noreferrer",className:"text-primary",children:"Paper Link"})]},n)}))})]})]})})},m=i(9603),p=function(e){e.title;var n=e.cards;return(0,t.jsx)("div",{id:"projects",className:"bg-primary py-5 px-5",children:(0,t.jsxs)("div",{className:"container",children:[(0,t.jsx)("h1",{className:"text-light fw-bold",children:"Projects"}),(0,t.jsx)("div",{className:"d-flex flex-row flex-wrap justify-content-center",children:n.map((function(e,n){return(0,t.jsx)(u,{title:e.title,description:e.description,icons:e.icons},n)}))})]})})},u=function(e){var n=e.title,i=e.description,a=e.icons;return(0,t.jsxs)("div",{className:"card py-3 px-3 mx-sm-4 my-4 card-work",style:{width:"20rem"},children:[(0,t.jsx)("h4",{className:"text-primary",children:n}),(0,t.jsx)("p",{className:"text-dark",children:i}),(0,t.jsx)("div",{className:"text-end",children:a&&a.map((function(e,n){return(0,t.jsx)(r(),{href:e.link,children:(0,t.jsx)("a",{target:"_blank",rel:"noreferrer",children:(0,t.jsx)(m.G,{className:"icon-style mx-1",icon:e.icon,size:"2x"})})},n)}))})]})},g=i(3193),x=i(4067),f=i(7673);function j(){return(0,t.jsxs)(a.Fragment,{children:[(0,t.jsx)(f.h,{seo:x.HJ}),(0,t.jsx)(o,{title:x.G.name,links:x.G.links}),(0,t.jsx)(c,{title:x.mf.title,description:x.mf.description,image:x.mf.image,buttons:x.mf.buttons}),(0,t.jsx)(d,{title:x.jZ.title,description:x.jZ.description}),(0,t.jsx)(p,{title:x.q.title,cards:x.q.cards}),(0,t.jsx)(h,{title:x.KK.title,description:x.KK.description,publications:x.KK.publications}),(0,t.jsx)(g.r,{title:x.PX.title,description:x.PX.description,buttons:x.PX.buttons}),(0,t.jsx)(g.$,{})]})}}},function(e){e.O(0,[948,574,603,774,888,179],(function(){return n=5557,e(e.s=n);var n}));var n=e.O();_N_E=n}]);