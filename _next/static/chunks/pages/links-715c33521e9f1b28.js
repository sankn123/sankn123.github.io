(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[935],{9916:function(e,n,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/links",function(){return t(4370)}])},3193:function(e,n,t){"use strict";t.d(n,{$:function(){return r},r:function(){return o}});var i=t(5893),a=(t(7294),t(1664)),s=t.n(a),o=function(e){var n=e.title,t=e.description,a=e.buttons;return(0,i.jsx)("div",{id:"contact",className:"bg-white py-5 px-5",children:(0,i.jsxs)("div",{className:"container",children:[(0,i.jsx)("h1",{className:"text-primary fw-bold",children:n}),(0,i.jsxs)("div",{className:"px-sm-5",children:[(0,i.jsx)("p",{children:t}),(0,i.jsx)("div",{className:"",children:a.map((function(e,n){return e.isPrimary?(0,i.jsx)(s(),{href:e.link,children:(0,i.jsx)("a",{className:"btn btn-primary my-1 mx-3",children:e.title})},n):(0,i.jsx)(s(),{href:e.link,children:(0,i.jsx)("a",{className:"btn btn-outline-primary my-1 mx-3",children:e.title})},n)}))})]})]})})},r=function(){return(0,i.jsx)("footer",{className:"bg-secondary text-center py-2 px-5",children:(0,i.jsx)("div",{className:"container text-muted"})})}},7673:function(e,n,t){"use strict";t.d(n,{h:function(){return o}});var i=t(5893),a=t(9008),s=t.n(a),o=function(e){var n=e.seo;return(0,i.jsxs)(s(),{children:[(0,i.jsx)("title",{children:n.title}),(0,i.jsx)("meta",{name:"description",content:n.description}),(0,i.jsx)("meta",{property:"og:title",content:n.title}),(0,i.jsx)("meta",{property:"og:description",content:n.description}),(0,i.jsx)("meta",{property:"og:image",content:n.image}),(0,i.jsx)("meta",{property:"og:type",content:"website"})]})}},4067:function(e,n,t){"use strict";t.d(n,{HJ:function(){return u},jZ:function(){return r},PX:function(){return d},mf:function(){return o},Ok:function(){return m},G:function(){return s},q:function(){return c},KK:function(){return l}});var i="/_next/static/media/profile.af9ecfc5.png",a=t(3024),s={name:"Home",links:[{title:"About",link:"#about"},{title:"Projects",link:"#projects"},{title:"Research",link:"#research"},{title:"Contact",link:"#contact"},{title:"Links",link:"/links"}]},o={title:"Hey, I'm Sankalp",description:"An electrical engineer focused on integrating AI into real-world applications.",image:i,buttons:[{title:"Contact Me",link:"#contact",isPrimary:!0},{title:"Resume",link:"https://drive.google.com/file/d/11f6X9eGAgBmm1V0r9n4nIGSM4tad4qDT/view?usp=sharing",isPrimary:!1}]},r={title:"Who I am",description:["I am a final-year B.Tech student at the Indian Institute of Technology, Dharwad, majoring in Electrical Engineering. I am currently working as a research assistant at IIT Dharwad, working on Computer Vision problems. I love reading new research papers and implementing their findings into practical applications, constantly pushing the boundaries of my knowledge.","Alongside my research, I have completed two internships at different startups, which I thoroughly enjoyed. I love the startup environment because of the sense of ownership it provides in developing and delivering the end-to-end product.","When I'm not diving into research, I enjoy playing football and spending time gaming\u2014though CSGO was my favorite until CS-2 ruined it!"]},c={title:"Some of my Projects",cards:[{title:"Adding AI generated voiceovers to silent videos",description:"An easy to use script that uses VideoDB for scene indexing, OpenAI for script generation, and ElevenLabs for realistic audio voiceovers, transforming silent footage into dynamic and engaging content.",icons:[{icon:a.zhw,link:"https://github.com/sankn123/AI-voiceovers-to-silent-videos"}]},{title:"Chandrayaan-2 Image Super-Resolution",description:"A project focused on enhancing the resolution of images using Generative AI from Indian Space Research Organisation-ISRO's Chandrayaan-2 mission using real-life data.",icons:[{icon:a.zhw,link:"https://github.com/snjvn/Moon_Mapping_Cosmosoc"}]},{title:"Paper Implementations",description:"Few of my implementations of key research papers in deep learning.",icons:[{icon:a.zhw,link:"https://github.com/sankn123/DCGAN-Implementation"},{icon:a.zhw,link:"https://github.com/sankn123/Very-deep-convolutional-networks-for-large-scale-image-recognition-Implementation"},{icon:a.zhw,link:"https://github.com/sankn123/Transformer-From-Scratch"}]}]},l={title:"Research Interests",description:["I am working as a research assistant at IIT Dharwad, and my research interests lie in Computer Vision, Generative AI, and Natural Language Processing (NLP)."],publications:[{title:"TM-PATHVQA: 90000+ Textless Multilingual Questions for Medical Visual Question Answering",description:"Published at Interspeech 2024. This work focuses on a speech-based VQA system with multilingual spoken questions. We proposed a dataset with 98,397 multilingual spoken questions and answers based on 5,004 pathological images along with 70 hours of audio, containing spoken questions in English, German & French. Finally, this work benchmarks and compares TM-PathVQA systems implemented using various combinations of acoustic and image features.",link:"https://www.isca-archive.org/interspeech_2024/rajkhowa24_interspeech.pdf"},{title:"AMamba: Enhancing Audio Reprsentation Learning Using State Space Model (Under Review)",description:"Submitted to Neurocomputing journal. This work introduces the first-ever Audio Mamba, a state-space model.",link:""},{title:"Adaptive Knowledge Fusion Ratio-Based Knowledge Distillation (Under Review)",description:"Submitted to Pattern Recognition journal. This work highlights a limitation of standard knowledge distillation and introduces a trainable approach to the fusion ratio.",link:""},{title:"BadScan: An Architectural Backdoor Attack on Visual State Space Models (Under Review)",description:"Submitted to Winter Conference on Applications of Computer Vision (WACV) conference.",link:""},{title:"When Visual State Space Model Meets Backdoor Attacks (Under Review)",description:"Submitted to Winter Conference on Applications of Computer Vision (WACV) conference.",link:""}]},d={title:"Get in touch",description:"Feel free to reach out directly by email at sankalp.nagaonkar@gmail.com.",buttons:[{title:"Email Me",link:"mailto:sankalp.nagaonkar@gmail.com",isPrimary:!0}]},u={title:"Sankalp Nagaonkar",image:i},m={image:i,title:"@sankn123",description:"Electrical Engineer | AI Enthusiast | Computer Vision and Generative AI",cards:[{title:"Twitter",link:"https://x.com/sankn123/"},{title:"GitHub",link:"https://github.com/sankn123/"},{title:"LinkedIn",link:"https://linkedin.com/in/sankalp-nagaonkar-18343823b/"},{title:"Google Scholar",link:"https://scholar.google.com/citations?user=sCr-DQgAAAAJ&hl=en"}]}},4370:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return m}});var i=t(5893),a=t(7294),s=t(1752),o=t.n(s),r=t(1664),c=t.n(r),l=t(3193),d=t(4067),u=t(7673);o()().publicRuntimeConfig;function m(){return(0,i.jsxs)(a.Fragment,{children:[(0,i.jsx)(u.h,{seo:d.HJ}),(0,i.jsxs)("div",{className:"d-flex flex-column justify-content-between bg-secondary min-vh-100",children:[(0,i.jsxs)("div",{className:"py-5 px-5 container text-center",children:[(0,i.jsx)("img",{className:"img-fluid my-3 card-image",width:"150",height:"150",src:d.Ok.image,alt:"profile of hashirshoaeb"}),(0,i.jsx)("h3",{className:"mt-3",children:d.Ok.title}),(0,i.jsx)("p",{children:d.Ok.description}),d.Ok.cards.map((function(e,n){return(0,i.jsx)(h,{title:e.title,link:e.link},n)}))]}),(0,i.jsx)(l.$,{})]})]})}function h(e){var n=e.title,t=e.link;return(0,i.jsx)("div",{className:"row justify-content-center",children:(0,i.jsx)("div",{className:"card card-work mx-sm-4 my-2",style:{width:"20rem"},children:(0,i.jsx)(c(),{href:t,children:(0,i.jsx)("a",{target:"_blank",rel:"noreferrer",children:(0,i.jsx)("h4",{className:"text-primary py-3 px-3",children:n})})})})})}}},function(e){e.O(0,[948,574,774,888,179],(function(){return n=9916,e(e.s=n);var n}));var n=e.O();_N_E=n}]);